version: "3.3"
networks:
  mynet:
    ipam:
      config:
      - subnet: 172.18.1.0/24
volumes:
  hadoop-config:
  spark-config:
services:
  hadoop-master:
    image: ghcr.io/ruixi-rebirth/hadoop-spark
    hostname: master
    ports:
      # - "9000:9000"
      - "50090:50090"
      # - "10020:10020"
      # - "19888:19888"
      # - "50070:50070"
      - "27649:27649"
      - "8080:8080"
      - "8088:8088"
    container_name: hadoop-master
    volumes:
      - hadoop-config:/home/hadoop/hadoop/etc/hadoop:rw
      - spark-config:/home/hadoop/spark/conf:rw
    restart: always
    stdin_open: true
    tty: true
    working_dir: /home/hadoop
    user: hadoop 
    # entrypoint: ./start-process.sh
    networks:
      mynet:
        ipv4_address: 172.18.1.2
    extra_hosts:
      - "master:172.18.1.2"
      - "slave1:172.18.1.3"
      - "slave2:172.18.1.4"
  hadoop-slave1:
    image: ghcr.io/ruixi-rebirth/hadoop-spark
    hostname: slave1
    container_name: hadoop-slave1
    volumes_from:
      - hadoop-master
    depends_on:
      - hadoop-master
    restart: always
    stdin_open: true
    tty: true
    working_dir: /home/hadoop
    user: hadoop 
    networks:
      mynet:
        ipv4_address: 172.18.1.3
    extra_hosts:
      - "master:172.18.1.2"
      - "slave1:172.18.1.3"
      - "slave2:172.18.1.4"
  hadoop-slave2:
    image: ghcr.io/ruixi-rebirth/hadoop-spark
    hostname: slave2
    container_name: hadoop-slave2
    volumes_from:
      - hadoop-master
    depends_on:
      - hadoop-master
    restart: always
    stdin_open: true
    tty: true
    working_dir: /home/hadoop
    user: hadoop 
    networks:
      mynet:
        ipv4_address: 172.18.1.4
    extra_hosts:
      - "master:172.18.1.2"
      - "slave1:172.18.1.3"
      - "slave2:172.18.1.4"

